{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SkinCancerClassification.ipynb","provenance":[],"mount_file_id":"160m1L1CJlbfcQ1AConLhdSNSDHIff4kE","authorship_tag":"ABX9TyO+3foT6qgesqdjGcd/zIuk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","id":"1gpoZtU5SZl7"},"outputs":[],"source":["# Bibliotecas Python\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","from glob import glob\n","from PIL import Image\n","\n","# Bibliotecas Pytorch\n","import torch\n","from torch import optim,nn\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader,Dataset\n","from torchvision import models,transforms\n","\n","# Bibliotecas Sklearn \n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","source":["# Define Argumentos a serem utilizados no treinamento \n","args = {'batch_size': 50,     #Tamanho do batch\n","        'lr': 1e-3,           #Taxa de aprendizado \n","        'weight_decay': 5e-4, #Penalidade L2\n","        'epoch_num': 100,     #Numero de epocas\n","        'num_workers': 2      \n","}\n","\n","if torch.cuda.is_available():\n","  args['device'] = torch.device('cuda')\n","else:\n","  args['device'] = torch.device('cpu')\n","\n","print(args['device'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i9Bsp7fjGHh3","executionInfo":{"status":"ok","timestamp":1657828548255,"user_tz":180,"elapsed":367,"user":{"displayName":"FELIPE DE MORAIS SOARES","userId":"00141569418557801967"}},"outputId":"9c293645-eb02-437a-b669-a611b90dde3f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"code","source":["# Código para montar o diretório do Google Drive \n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"DxhoT3AuBleS"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","id":"B8zFExHNSZl-"},"outputs":[],"source":["# Acessa os arquivos no local do drive e monta um path com o caminho de cada imagem\n","data_dir = \"/content/drive/MyDrive/dataset/\"\n","all_image_path = glob(os.path.join(data_dir, '*', '*.jpg'))\n","imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x for x in all_image_path}\n","lesion_type_dict = {\n","    'nv': 'Nevo Melanotico',\n","    'mel': 'Melanoma',\n","    'bkl': 'Queratose Seborreia',\n","    'bcc': 'Carcinoma',\n","    'akiec': 'Queratose Actinica',\n","    'vasc': 'Lesao Vascular',\n","    'df': 'Dermatofibroma'\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GkDVLPtDSZl_"},"outputs":[],"source":["# Código para calcular média e desvio padrão, foi utilizado uma vez e salvo os valores para o HAM10000\n","def calcular_img_mean_std(image_paths):   \n","    img_h, img_w = 224, 224\n","    imgs = []\n","    means, stdevs = [], []\n","\n","    for i in tqdm(range(len(image_paths))):\n","        img = cv2.imread(image_paths[i])\n","        img = cv2.resize(img, (img_h, img_w))\n","        imgs.append(img)\n","\n","    imgs = np.stack(imgs, axis=3)\n","    print(imgs.shape)\n","\n","    imgs = imgs.astype(np.float32) / 255.\n","\n","    for i in range(3):\n","        pixels = imgs[:, :, i, :].ravel() \n","        means.append(np.mean(pixels))\n","        stdevs.append(np.std(pixels))\n","\n","    means.reverse()  # BGR --> RGB \n","    stdevs.reverse()\n","\n","    print(\"normMean = {}\".format(means))\n","    print(\"normStd = {}\".format(stdevs))\n","    return means,stdevs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n-OHw7uVSZmA"},"outputs":[],"source":["# Aciona a função para norma e desvio \n","norm_mean,norm_std = compute_img_mean_std(all_image_path)"]},{"cell_type":"code","source":["# Identifica se tem lesões com id duplicados \n","def get_duplicates(x):\n","    unique_list = list(df_undup['lesion_id'])\n","    if x in unique_list:\n","        return 'unduplicated'\n","    else:\n","        return 'duplicated'"],"metadata":{"id":"U3_K9e2rBa55"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZbApwm2fSZmB"},"outputs":[],"source":["# Pré processamento dos metadados \n","df_original = pd.read_csv(os.path.join(data_dir, 'HAM10000_metadata.csv'))\n","df_original['path'] = df_original['image_id'].map(imageid_path_dict.get)\n","df_original['cell_type'] = df_original['dx'].map(lesion_type_dict.get)\n","df_original['cell_type_idx'] = pd.Categorical(df_original['cell_type']).codes\n","df_original.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"znMwnVNYSZmB"},"outputs":[],"source":["\n","df_undup = df_original.groupby('lesion_id').count()\n","df_undup = df_undup[df_undup['image_id'] == 1]\n","df_undup.reset_index(inplace=True)\n","df_undup.head()\n","\n","\n","# Aplica a função para verificar duplicações para os Id's \n","df_original['duplicates'] = df_original['lesion_id']\n","df_original['duplicates'] = df_original['duplicates'].apply(get_duplicates)\n","df_original.head()\n","df_original['duplicates'].value_counts()\n","df_undup = df_original[df_original['duplicates'] == 'unduplicated']\n","df_undup.shape\n","\n","# Separação de teste\n","y = df_undup['cell_type_idx']\n","_, df_val = train_test_split(df_undup, test_size=0.2, random_state=101, stratify=y)\n","df_val.shape\n","\n","df_val['cell_type_idx'].value_counts()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3S91AO-LSZmE"},"outputs":[],"source":["# Este conjunto será df_original excluindo todas as linhas que estão no conjunto val\n","# Esta função identifica se uma imagem faz parte do conjunto train ou val.\n","def get_val_rows(x):\n","    val_list = list(df_val['image_id'])\n","    if str(x) in val_list:\n","        return 'val'\n","    else:\n","        return 'train'\n","\n","# identificar linhas de trem e val\n","df_original['train_or_val'] = df_original['image_id']\n","df_original['train_or_val'] = df_original['train_or_val'].apply(get_val_rows)\n","# df de treino\n","df_train = df_original[df_original['train_or_val'] == 'train']\n","print(len(df_train))\n","print(len(df_val))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y3aD1dbGSZmE"},"outputs":[],"source":["df_train['cell_type_idx'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OiIZLnWtSZmE"},"outputs":[],"source":["df_val['cell_type'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"atVa6FezSZmF"},"outputs":[],"source":["# DataAugmentation realizado para o balanceamento das classes\n","data_aug_rate = [15,10,5,50,0,40,5]\n","for i in range(7):\n","    if data_aug_rate[i]:\n","        df_train=df_train.append([df_train.loc[df_train['cell_type_idx'] == i,:]]*(data_aug_rate[i]-1), ignore_index=True)\n","df_train['cell_type'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"miIU1uxzSZmF"},"outputs":[],"source":["df_train = df_train.reset_index()\n","df_val = df_val.reset_index()"]},{"cell_type":"code","source":["df_val.to_csv('val_depois_aug.csv')\n","df_train.to_csv('train_depois_aug.csv')"],"metadata":{"id":"RWq_Tl1o-opK"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xEtGSrZcSZmG"},"outputs":[],"source":["# Definição das 3 Arquiteturas Pré-Carregadas pela bilbioteca Pytorch \n","def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n","    model_ft = None\n","    input_size = 0\n","\n","    if model_name == \"resnet\":\n","        #Resnet50\n","        \n","        model_ft = models.resnet50(pretrained=use_pretrained)\n","        set_parameter_requires_grad(model_ft, feature_extract)\n","        num_ftrs = model_ft.fc.in_features\n","        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n","        input_size = 224\n","\n","\n","    elif model_name == \"vgg\":\n","        # VGG11_bn\n","        \n","        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n","        set_parameter_requires_grad(model_ft, feature_extract)\n","        num_ftrs = model_ft.classifier[6].in_features\n","        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n","        input_size = 224\n","\n","\n","    elif model_name == \"densenet\":\n","        # Densenet121\n","        \n","        model_ft = models.densenet121(pretrained=use_pretrained)\n","        set_parameter_requires_grad(model_ft, feature_extract)\n","        num_ftrs = model_ft.classifier.in_features\n","        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n","        input_size = 224\n","\n","    else:\n","        print(\"Invalid model name, exiting...\")\n","        exit()\n","    return model_ft, input_size\n","\n","def set_parameter_requires_grad(model, feature_extracting):\n","    if feature_extracting:\n","        for param in model.parameters():\n","            param.requires_grad = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0GkS6HtqSZmG","executionInfo":{"status":"ok","timestamp":1654108664547,"user_tz":180,"elapsed":726,"user":{"displayName":"FELIPE DE MORAIS SOARES","userId":"00141569418557801967"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"458ab89d-1e51-4ce9-fa50-4ddf06d5c7b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}],"source":["# Define a Arquitetura a ser treinada \n","model_name = 'densenet'\n","num_classes = 7\n","feature_extract = False\n","\n","model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n","model = model_ft.to(args['device'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ulWJrYsLSZmH"},"outputs":[],"source":["# Realiza as transformações dos sets de treino e validação \n","# Os valores de média e desvio feitas pela função calcular_img_mean_std\n","\n","norm_mean = (0.76310134, 0.5456841, 0.57007784)\n","norm_std = (0.14092982, 0.1526007, 0.16996273)\n","\n","\n","train_transform = transforms.Compose([transforms.Resize((input_size,input_size)),transforms.RandomHorizontalFlip(),\n","                                      transforms.RandomVerticalFlip(),transforms.RandomRotation(20),\n","                                      transforms.ColorJitter(brightness=0.1, contrast=0.1, hue=0.1),\n","                                        transforms.ToTensor(), transforms.Normalize(norm_mean, norm_std)])\n","\n","val_transform = transforms.Compose([transforms.Resize((input_size,input_size)), transforms.ToTensor(),\n","                                    transforms.Normalize(norm_mean, norm_std)])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"loOzzFyfSZmH"},"outputs":[],"source":["# Define dataloader classe para carregamento das imagens\n","class HAM10000(Dataset):\n","    def __init__(self, df, transform=None):\n","        self.df = df\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, index):\n","        # Load data and get label\n","        X = Image.open(self.df['path'][index])\n","        y = torch.tensor(int(self.df['cell_type_idx'][index]))\n","\n","        if self.transform:\n","            X = self.transform(X)\n","\n","        return X, y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ci5_Lw32SZmH"},"outputs":[],"source":["training_set = HAM10000(df_train, transform=train_transform)\n","train_loader = DataLoader(training_set, batch_size=args['batch_size'], shuffle=True, num_workers=args['num_workers'])\n","\n","validation_set = HAM10000(df_val, transform=train_transform)\n","val_loader = DataLoader(validation_set, batch_size=args['batch_size'], shuffle=False, num_workers=args['num_workers'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GzmBce0_SZmH"},"outputs":[],"source":["# Adam Otimizados and Cross Entropy critério de perda\n","optimizer = optim.Adam(model.parameters(), lr=num_workers=args['lr'])\n","criterion = nn.CrossEntropyLoss().to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TLi-PRP-SZmI"},"outputs":[],"source":["# Realiza calculos dos resultados \n","class AverageMeter(object):\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fAH1oBv7SZmI"},"outputs":[],"source":["total_loss_train, total_acc_train = [],[]\n","def train(train_loader, model, criterion, optimizer, epoch):\n","    model.train()\n","    train_loss = AverageMeter()\n","    train_acc = AverageMeter()\n","    curr_iter = (epoch - 1) * len(train_loader)\n","    for i, data in enumerate(train_loader):\n","        images, labels = data\n","        N = images.size(0)\n","        # print('image shape:',images.size(0), 'label shape',labels.size(0))\n","        images = Variable(images).to(device)\n","        labels = Variable(labels).to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        prediction = outputs.max(1, keepdim=True)[1]\n","        train_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n","        train_loss.update(loss.item())\n","        curr_iter += 1\n","        if (i + 1) % 100 == 0:\n","            print('[epoch %d], [iter %d / %d], [train loss %.5f], [train acc %.5f]' % (\n","                epoch, i + 1, len(train_loader), train_loss.avg, train_acc.avg))\n","            total_loss_train.append(train_loss.avg)\n","            total_acc_train.append(train_acc.avg)\n","    return train_loss.avg, train_acc.avg"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iW2CfxepSZmI"},"outputs":[],"source":["def validate(val_loader, model, criterion, optimizer, epoch):\n","    model.eval()\n","    val_loss = AverageMeter()\n","    val_acc = AverageMeter()\n","    with torch.no_grad():\n","        for i, data in enumerate(val_loader):\n","            images, labels = data\n","            N = images.size(0)\n","            images = Variable(images).to(device)\n","            labels = Variable(labels).to(device)\n","\n","            outputs = model(images)\n","            prediction = outputs.max(1, keepdim=True)[1]\n","\n","            val_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n","\n","            val_loss.update(criterion(outputs, labels).item())\n","\n","    print('------------------------------------------------------------')\n","    print('[epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, val_loss.avg, val_acc.avg))\n","    print('------------------------------------------------------------')\n","    return val_loss.avg, val_acc.avg"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1W3KdG_pSZmI"},"outputs":[],"source":["epoch_num = args['epoch_num']\n","best_val_acc = 0\n","total_loss_val, total_acc_val = [],[]\n","for epoch in range(1, epoch_num+1):\n","    loss_train, acc_train = train(train_loader, model, criterion, optimizer, epoch)\n","    loss_val, acc_val = validate(val_loader, model, criterion, optimizer, epoch)\n","    total_loss_val.append(loss_val)\n","    total_acc_val.append(acc_val)\n","    if acc_val > best_val_acc:\n","        best_val_acc = acc_val\n","        print('*****************************************************')\n","        print('best record: [epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, loss_val, acc_val))\n","        print('*****************************************************')\n","\n","print(\"Final Process!!!\")"]},{"cell_type":"code","source":["print(len(total_loss_train))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RLo6uNPCLr7m","executionInfo":{"status":"ok","timestamp":1652946597163,"user_tz":180,"elapsed":2,"user":{"displayName":"FELIPE DE MORAIS SOARES","userId":"00141569418557801967"}},"outputId":"27d404e7-63cc-414d-ae7e-9bcf945cd056"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["110\n"]}]},{"cell_type":"markdown","source":["**SOME PLOTS**\n","\n"],"metadata":{"id":"Kqkj-1gBaDIl"}},{"cell_type":"code","source":["plt.figure(figsize=(20, 9))\n","plt.plot(total_loss_train, label='Train Loss')\n","plt.plot(total_acc_train, label='Train Accuracy', linewidth=3, alpha=0.5)\n","plt.xlabel('Epochs', fontsize=16)\n","plt.ylabel('Loss', fontsize=16)\n","plt.title('VGG Training', fontsize=16)\n","plt.legend()\n","plt.show()"],"metadata":{"id":"m7gly-t0TAtA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(20, 9))\n","plt.plot(total_loss_val, label='Validation Loss')\n","plt.plot(total_acc_val, label='Validation Accuracy', linewidth=3, alpha=0.5)\n","plt.xlabel('Epochs', fontsize=16)\n","plt.ylabel('Loss', fontsize=16)\n","plt.title('VGG Validation', fontsize=16)\n","plt.legend()\n","plt.show()"],"metadata":{"id":"nrNedDHfJwQV"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"elRCKuJRSZmJ"},"outputs":[],"source":["fig = plt.figure(num = 2)\n","fig1 = fig.add_subplot(2,1,1)\n","fig2 = fig.add_subplot(2,1,2)\n","fig1.plot(total_loss_train, label = 'training loss')\n","fig1.plot(total_acc_train, label = 'training accuracy')\n","fig2.plot(total_loss_val, label = 'validation loss')\n","fig2.plot(total_acc_val, label = 'validation accuracy')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","source":["**SAVE MODEL**"],"metadata":{"id":"IRz91CixaIpg"}},{"cell_type":"code","source":["# Salva o modelo treinado para deploy\n","torch.save(model, 'model_vgg')"],"metadata":{"id":"8ltOLx4TVJuf"},"execution_count":null,"outputs":[]}]}